{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Import Libraries","metadata":{}},{"cell_type":"code","source":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns \nfrom tqdm.auto import tqdm \n\n\nimport nltk \nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer \nimport re \nfrom collections import Counter\nfrom string import punctuation\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelEncoder \nfrom sklearn.metrics import precision_score, recall_score , f1_score, accuracy_score,confusion_matrix\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n\nfrom gensim.models import Word2Vec\nimport torch \nimport torch.nn as nn  \nfrom torch.optim import Adam\nfrom torch.utils.data import DataLoader , TensorDataset\nfrom torchmetrics import ConfusionMatrix \nfrom mlxtend.plotting import plot_confusion_matrix\n\nlemma = WordNetLemmatizer()\nlb = LabelEncoder()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Loading Dataset","metadata":{}},{"cell_type":"code","source":"df = pd.read_csv('twitter_training.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(df['Borderlands'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"np.unique(df['Positive'])","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df.drop('2401' , axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df= df.rename(columns={\"Borderlands\":\"Feature2\",\"im getting on borderlands and i will murder you all ,\":\"Feature1\",\"Positive\": \"labels\"})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df[\"tweets\"]= df[\"Feature1\"].astype(str) +\" \"+ df[\"Feature2\"].astype(str)\ndf= df.drop([\"Feature1\",\"Feature2\"],axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df_labels = {key : value for value , key in enumerate(np.unique(df['labels']))}\ndf_labels","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def getlabel(n) : \n    for x , y in df_labels.items() : \n        if y==n : \n            return x","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# EDA","metadata":{}},{"cell_type":"code","source":"label_count = df['labels'].value_counts()\nfig,axes = plt.subplots(nrows=1, ncols=2, figsize=(20,6))\n\nsns.set_theme(style='darkgrid', palette='pastel')\ncolor = sns.color_palette(palette='pastel')\nexplode = [0.02]*len(label_count)\n\naxes[0].pie(label_count.values, labels=label_count.index, autopct='%1.1f%%', colors=color, explode=explode)\naxes[0].set_title('Percentage Label')\n\nsns.countplot(df['labels'] , ax=axes[1])\naxes[1].set_title('Count Label')\naxes[1].set_xlabel('Label')\naxes[1].set_ylabel('Count')\n\nplt.tight_layout()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def Most_Words_used(tweets , num_of_words) : \n    all_text = ''.join(df[tweets].values) \n    \n    all_text = re.sub('<.*?>', '', all_text) # HTML tags\n    all_text = re.sub(r'\\d+', '', all_text) # numbers\n    all_text = re.sub(r'[^\\w\\s]', '', all_text) # special characters\n    all_text = re.sub(r'http\\S+', '', all_text) # URLs or web links\n    all_text = re.sub(r'@\\S+', '', all_text) # mentions\n    all_text = re.sub(r'#\\S+', '', all_text) # hashtags\n    \n    words = all_text.split() \n    \n    # remove puncs \n    punc = list(punctuation) \n    words = [word for word in words if word not in punc]\n    \n    # remove stopwords \n    stop_words = set(stopwords.words('english'))\n    words = [word for word in words if not word in stop_words]\n    \n    word_counts = Counter(words)\n    \n    top_words = word_counts.most_common(num_of_words)\n    \n    return top_words","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"top_words = Most_Words_used('tweets' , 50)\n\nxaxis = [word[0] for word in top_words]\nyaxis = [word[1] for word in top_words]\n\nplt.figure(figsize=(16,5))\nplt.bar(xaxis , yaxis)\nplt.xlabel('Word')\nplt.ylabel('Frequency')\nplt.title('Most Commonly Used Words', fontsize=25)\nplt.xticks(rotation=65)\nplt.subplots_adjust(bottom=0.15)\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Data Preprocessing","metadata":{}},{"cell_type":"code","source":"def DataPrep(text) : \n    text = re.sub('<.*?>', '', text) # HTML tags\n    text = re.sub(r'\\d+', '', text) # numbers\n    text = re.sub(r'[^\\w\\s]', '', text) # special characters\n    text = re.sub(r'http\\S+', '', text) # URLs or web links\n    text = re.sub(r'@\\S+', '', text) # mentions\n    text = re.sub(r'#\\S+', '', text) # hashtags\n    \n    # tokenization \n    tokens = nltk.word_tokenize(text) \n    \n    # remove puncs \n    punc = list(punctuation)\n    words = [word for word in tokens if word not in punc]\n    \n    # remove stopwords \n    stop_words = set(stopwords.words('english'))\n    words = [word for word in words if not word.lower() in stop_words]\n    \n    # Lemmatization \n    words = [lemma.lemmatize(word) for word in words] \n    \n    text = ' '.join(words)\n    \n    return text","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['cleaned_tweets'] = df['tweets'].apply(DataPrep)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f'There are around {int(df[\"cleaned_tweets\"].duplicated().sum())} duplicated tweets, we will remove them.')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df.drop_duplicates(\"cleaned_tweets\", inplace=True)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df['tweet_len'] = [len(text.split()) for text in df.cleaned_tweets]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df = df[df['tweet_len'] < df['tweet_len'].quantile(0.995)]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.figure(figsize=(16,5))\nax = sns.countplot(x='tweet_len', data=df[(df['tweet_len']<=1000) & (df['tweet_len']>10)], palette='Blues_r')\nplt.title('Count of tweets with high number of words', fontsize=25)\nplt.yticks([])\nax.bar_label(ax.containers[0])\nplt.ylabel('count')\nplt.xlabel('')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Split the data","metadata":{}},{"cell_type":"code","source":"x_train , x_val , y_train , y_val = train_test_split(df['cleaned_tweets'] , df['labels'] , train_size = 0.85 , random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(x_train) , len(x_val)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Feature Extraction","metadata":{}},{"cell_type":"code","source":"vec = TfidfVectorizer()\nvec.fit(x_train)\nprint(\"No. of feature words: \",len(vec.get_feature_names()))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"x_train = vec.transform(x_train).toarray()\nx_val = vec.transform(x_val).toarray()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Encoding","metadata":{}},{"cell_type":"code","source":"y_train = lb.fit_transform(y_train)\ny_val = lb.fit_transform(y_val)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Logistic Regression","metadata":{}},{"cell_type":"code","source":"lr = LogisticRegression(random_state=42)\nlr.fit(x_train , y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_acc1 = lr.score(x_train , y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_pred = lr.predict(x_val)\n\nval_acc1 = accuracy_score(y_val , lr_pred) \n\nval_precision1 = precision_score(y_val , lr_pred , average='weighted')\nval_recall1 = recall_score(y_val , lr_pred , average='weighted')\nval_f1score1 = f1_score(y_val , lr_pred , average='weighted')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"The training accuracy for logistic regression : {(train_acc1*100):0.2f}%\\n\")\nprint(f\"The validation accuracy for logistic regression : {(val_acc1*100):0.2f}%\\n\")\nprint(f\"The precision for logistic regression : {val_precision1:0.2f}\\n\")\nprint(f\"The recall for logistic regression : {val_recall1:0.2f}\\n\")\nprint(f\"The f1 score for logistic regression : {val_f1score1:0.2f}\\n\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr_cm = confusion_matrix(y_val , lr_pred)\nsns.heatmap(lr_cm, annot=True,fmt='3g')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Random Forest Classifier","metadata":{}},{"cell_type":"code","source":"rf = RandomForestClassifier()\nrf.fit(x_train , y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_acc2 = rf.score(x_train , y_train)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_pred = rf.predict(x_val)\n\nval_acc2 = accuracy_score(y_val , lr_pred) \n\nval_precision2 = precision_score(y_val , rf_pred , average='weighted')\nval_recall2 = recall_score(y_val , rf_pred , average='weighted')\nval_f1score2 = f1_score(y_val , rf_pred , average='weighted')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"The training accuracy for Random Forest : {(train_acc2*100):0.2f}%\\n\")\nprint(f\"The validation accuracy for Random Forest : {(val_acc2*100):0.2f}%\\n\")\nprint(f\"The precision for Random Forest : {val_precision2:0.2f}\\n\")\nprint(f\"The recall for Random Forest : {val_recall2:0.2f}\\n\")\nprint(f\"The f1 score for Random Forest : {val_f1score2:0.2f}\\n\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"rf_cm = confusion_matrix(y_val , rf_pred)\nsns.heatmap(lr_cm, annot=True,fmt='3g')\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# LSTM","metadata":{}},{"cell_type":"markdown","source":"Data preprocessing for LSTM","metadata":{}},{"cell_type":"code","source":"MAX_LEN = np.max(df['tweet_len'])\nMAX_LEN","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def lstm_prep(column , seq_len) : \n    # create a vocab of words \n    corpus = [word for text in column for word in text.split()]\n    words_count = Counter(corpus) \n    sorted_words = words_count.most_common()\n    vocab_to_int = {w:i+1 for i , (w,c) in enumerate(sorted_words)}\n    \n    text_int = [] \n    \n    for text in column : \n        token = [vocab_to_int[word] for word in text.split()]\n        text_int.append(token)\n        \n        \n    # padding \n    features = np.zeros((len(text_int) , seq_len) , dtype = int)\n    for idx , y in tqdm(enumerate(text_int)) : \n        if len(y) <= seq_len : \n            zeros = list(np.zeros(seq_len - len(y)))\n            new = zeros + y\n            \n        else : \n            new = y[:seq_len]\n            \n        features[idx,:] = np.array(new)\n        \n    return sorted_words, features","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VOCAB , tokenized_column = lstm_prep(df['cleaned_tweets'] , MAX_LEN)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"VOCAB[:10]","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(VOCAB)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"tokenized_column.shape","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def most_common_words(vocab) : \n    keys = [] \n    values = [] \n    for key , value in vocab[:30] : \n        keys.append(key) \n        values.append(value)\n        \n    plt.figure(figsize=(15, 5))\n    ax = sns.barplot(keys, values, palette='mako')\n    plt.title('Top 20 most common words', size=25)\n    ax.bar_label(ax.containers[0])\n    plt.ylabel(\"Words count\")\n    plt.xticks(rotation=45)\n    plt.subplots_adjust(bottom=0.15)\n    plt.show()\n    \nmost_common_words(VOCAB)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X = tokenized_column\ny = lb.fit_transform(df['labels'].values)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_train , X_val , Y_train , Y_val = train_test_split(X , y , train_size=0.85 , random_state=42)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_data = TensorDataset(torch.from_numpy(X_train), torch.LongTensor(Y_train))\nval_data = TensorDataset(torch.from_numpy(X_val), torch.LongTensor(Y_val))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Create DataLoaders","metadata":{}},{"cell_type":"code","source":"BATCH_SIZE = 64","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(42)\ntrain_dataloader = DataLoader(\n    dataset = train_data , \n    batch_size=BATCH_SIZE , \n    shuffle=True\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"torch.manual_seed(42) \nval_dataloader = DataLoader(\n    dataset = val_data , \n    batch_size = BATCH_SIZE , \n    shuffle=False\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"the size of the train dataloader {len(train_dataloader)} batches of {BATCH_SIZE}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"the size of the validation dataloader {len(val_dataloader)} batches of {BATCH_SIZE}\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Word Embedding by Word2Vec","metadata":{}},{"cell_type":"code","source":"EMBEDDING_DIM = 200","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"Word2vec_train_data = list(map(lambda x: x.split(), df['cleaned_tweets']))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"word2vec_model = Word2Vec(Word2vec_train_data, vector_size=EMBEDDING_DIM)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def weight_matrix(model,vocab):\n    vocab_size= len(vocab)+1\n    embedding_matrix = np.zeros((vocab_size,EMBEDDING_DIM))\n    for word, token in vocab:\n        if model.wv.__contains__(word):\n            embedding_matrix[token]=model.wv.__getitem__(word)\n    return embedding_matrix","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"embedding_vec = weight_matrix(word2vec_model,VOCAB)\nprint(\"Embedding Matrix Shape:\", embedding_vec.shape)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Build our model","metadata":{}},{"cell_type":"code","source":"def param_count(model):\n    params = [p.numel() for p in model.parameters() if p.requires_grad]\n    print('The Total number of parameters in the model : ', sum(params))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class LSTM(nn.Module) : \n    def __init__(self , vocab_size , embedding_dim \n                 , num_layers , hidden_dim , out_channels , bidirectional) : \n        super().__init__() \n         \n        self.no_layers = num_layers \n        self.hidden_dim = hidden_dim \n        self.out_channels = out_channels\n        self.num_directions = 2 if bidirectional else 1  \n        self.embedding = nn.Embedding(vocab_size , embedding_dim)\n        \n        self.lstm = nn.LSTM(\n            embedding_dim , \n            hidden_dim , \n            num_layers , \n            dropout = 0.5 , \n            bidirectional = bidirectional , \n            batch_first = True\n        )\n        \n        self.fc = nn.Linear(hidden_dim*self.num_directions , out_channels)\n        \n        \n    def forward(self , x) : \n        h0 = torch.zeros((self.no_layers * self.num_directions , x.size(0) , self.hidden_dim))\n        c0 = torch.zeros((self.no_layers * self.num_directions , x.size(0) , self.hidden_dim))\n        \n        embedded = self.embedding(x)\n        \n        out , _ = self.lstm(embedded , (h0 , c0))\n        \n        out = out[:,-1,:]\n        \n        out = self.fc(out)\n        \n        return out ","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# define parameters \nVOCAB_SIZE = len(VOCAB) + 1\nNUM_LAYERS = 2 \nOUT_CHANNELS = 4 \nHIDDEN_DIM = 256\nBIDIRECTIONAL = True\n\nmodel = LSTM(VOCAB_SIZE , EMBEDDING_DIM , NUM_LAYERS , HIDDEN_DIM , OUT_CHANNELS , BIDIRECTIONAL)\n\nmodel.embedding.weight.data.copy_(torch.from_numpy(embedding_vec))\n\nmodel.embedding.weight.requires_grad = True","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"param_count(model)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"criterion=nn.CrossEntropyLoss()\noptimizer=Adam(model.parameters(),lr=0.001)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Train our model","metadata":{}},{"cell_type":"code","source":"epochs = 10 \ntraining_loss = []\ntraining_acc = [] \nfor i in tqdm(range(epochs)) : \n    epoch_loss = 0\n    epoch_acc = 0 \n    for batch , (x_train , y_train) in enumerate(train_dataloader) : \n        y_pred = model(x_train)\n        \n        loss = criterion(y_pred , y_train) \n        \n        if batch % 500 == 0:\n            print(f\"Looked at {batch * len(x_train)}/{len(train_dataloader.dataset)} samples.\")\n            \n        loss.backward()\n        optimizer.step()\n        optimizer.zero_grad()\n        \n        epoch_loss +=loss \n        epoch_acc += accuracy_score(y_train , y_pred.argmax(dim=1))\n        \n    training_loss.append((epoch_loss/len(train_dataloader)).detach().numpy())\n    training_acc.append(epoch_acc/len(train_dataloader))\n    \n    print(f\"Epoch {i+1}: Accuracy: {(epoch_acc/len(train_dataloader)) * 100}, Loss: {(epoch_loss/len(train_dataloader))}\\n\\n\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(f\"The loss of the training set is : {training_loss[-1]:0.2f}\")\nprint(f\"The accuracy of the training set is : {(training_acc[-1]*100):0.2f}%\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"plt.plot(range(epochs),training_loss,color=\"blue\",label=\"Loss\")\nplt.plot(range(epochs),training_acc,color=\"green\",label=\"Accuracy\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy / Loss')\nplt.legend()\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Test our model","metadata":{}},{"cell_type":"code","source":"val_loss=0\nval_acc3= 0\nlstm_preds=[]\nval_targets = []\ntorch.manual_seed(42)\nwith torch.no_grad() : \n        for x_val , y_val in tqdm(val_dataloader) : \n            y_pred=model.forward(x_val)\n            val_pred = torch.softmax(y_pred , dim=1 ).argmax(dim=1)\n            lstm_preds.append(val_pred)\n            val_targets.extend(y_val)\n            \n            loss=criterion(y_pred,y_val)\n            val_loss+=loss\n            val_acc3 += accuracy_score(y_val , y_pred.argmax(dim=1))\n            \n            \nval_loss/=len(val_dataloader)\nval_acc3/=len(val_dataloader)\nlstm_preds = torch.cat(lstm_preds)\nval_targets = torch.Tensor(val_targets)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"train_acc3 = training_acc[-1]\nval_precision3 = precision_score(val_targets,lstm_preds,average='weighted')\nval_recall3 = recall_score(val_targets,lstm_preds,average='weighted')\nval_f1score3 = f1_score(val_targets,lstm_preds,average='weighted')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Measuring performance","metadata":{}},{"cell_type":"code","source":"print(f\"The training accuracy for LSTM : {(train_acc3*100):0.2f}%\\n\")\nprint(f\"The validation accuracy for LSTM : {(val_acc3*100):0.2f}%\\n\")\nprint(f\"The precision for LSTM : {val_precision3:0.2f}\\n\")\nprint(f\"The recall for LSTM : {val_recall3:0.2f}\\n\")\nprint(f\"The f1 score for LSTM : {val_f1score3:0.2f}\\n\")\nprint(f\"The training loss for LSTM : {training_loss[-1]:0.2f}\\n\")\nprint(f\"The validation loss for LSTM : {val_loss:0.2f}\\n\")","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"confmat = ConfusionMatrix(num_classes=4, task='multiclass')\nconfmat_tensor = confmat(preds=lstm_preds,\n                         target=val_targets)\n\nfig, ax = plot_confusion_matrix(\n    conf_mat=confmat_tensor.numpy(),\n    class_names=df_labels.keys(),\n    figsize=(10, 7)\n)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Compare between models","metadata":{}},{"cell_type":"code","source":"train_scores=[train_acc1,train_acc2,train_acc3]\nval_scores=[val_acc1,val_acc2,val_acc3]\n\nmodels = ['Logistic Regression','RandomForest','LSTM']\n\nx = np.arange(len(models))\n\nwidth = 0.25\n\nfig, ax = plt.subplots(figsize=(20, 10))\n\nrects1 = ax.bar(x - width, train_scores, width, label='Train Accuracy')\n\nrects2 = ax.bar(x + width, val_scores, width, label='Validation Accuracy')\n\nax.set_xlabel('Models')\nax.set_ylabel('Accuracy')\nax.set_title('Comparison of Training and Validation Accuracies')\nax.set_xticks(x)\nax.set_xticklabels(models)\nax.legend()\n\ndef autolabel(rects):\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{:.3f}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() / 2, height),\n                    xytext=(0, 2),\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\n\nautolabel(rects1)\nautolabel(rects2)\n\nplt.show()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# make predictions","metadata":{}},{"cell_type":"code","source":"test_df = pd.read_csv('twitter_validation.csv')","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.columns","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df = test_df.drop('3364' , axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df= test_df.rename(columns={\"Facebook\":\"Feature2\",\"I mentioned on Facebook that I was struggling for motivation to go for a run the other day, which has been translated by Tomâ€™s great auntie as â€˜Hayley canâ€™t get out of bedâ€™ and told to his grandma, who now thinks Iâ€™m a lazy, terrible person ðŸ¤£\":\"Feature1\",\"Irrelevant\": \"labels\"})","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df[\"tweets\"]= test_df[\"Feature1\"].astype(str) +\" \"+ test_df[\"Feature2\"].astype(str)\ntest_df= test_df.drop([\"Feature1\",\"Feature2\"],axis=1)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_df.head()","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def make_predictions(row) : \n    random_data = row.sample(n=10)\n    random_tweets = random_data['tweets'].values\n    \n    cleaned_tweets = [] \n    for tweet in random_tweets : \n        cleaned_tweets.append(DataPrep(tweet))\n        \n    x_test = vec.transform(cleaned_tweets).toarray()\n    \n    y_test = random_data['labels'].values\n    \n    lr_pred = lr.predict(x_test)\n    \n    rf_pred = rf.predict(x_test) \n        \n    _ , X_test = lstm_prep(cleaned_tweets , MAX_LEN)\n    \n    X_test = torch.from_numpy(X_test)\n\n    lstm_pred = model(X_test)\n    lstm_pred = torch.softmax(lstm_pred , dim=1 ).argmax(dim=1)\n    \n    for i in tqdm(range(10)) : \n        print(f\"The original tweet : {random_tweets[i]}\\n\")\n        print(f\"The original label : {y_test[i]}\\n\")\n        print(f\"The lr prediction is : {getlabel(lr_pred[i])}\\n\")\n        print(f\"The rf prediction is : {getlabel(rf_pred[i])}\\n\")\n        print(f\"The lstm prediction is : {getlabel(lstm_pred[i])}\\n\")\n        print('-'*120)\n    \n    \nmake_predictions(test_df)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}